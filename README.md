# Serve pytorch using Flask

- experimenting (eventually will go into production)
- options
    - do this
        - need to have gpu on the server, to do inference. ~ 4s response on Tesla K80 
    - deploy pytorch model directly on iOS because we all love ARM.

- https://www.youtube.com/watch?v=Fig9ZBQaXK8
